# -*- coding: utf-8 -*-
"""DAHW5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ccfMJ8k2n11b35sg6ul2pvsJxqw6kInF

#Download the dataset airline-passengers.csv
"""

from google.colab import files #This cell is used when running this code on Google Colab Platform
#uploaded = files.upload()

"""#Import Libraries"""

import numpy
import pandas
import math
import matplotlib.pyplot as plt
import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler

"""#a) Plot the time series data"""

# load  and plot the dataset excluding the first column
dataframe = pandas.read_csv('airline-passengers.csv', usecols=[1], engine='python')
plt.plot(dataframe)
plt.show()

"""#b) Explain the short-term and long-term temporal patterns

As the time series plot in part a it is clear that the **long-term temporal patterns are generally in a rising trend**, whereas the **short-term temporal patterns fluctuates periodically within the rising trend** it may be correlated to spikes in travelling in times of holidays and vacations throughout the year

#c) Build an LSTM network
"""

#A function that converts an array of values into a dataset matrix
def create_dataset(dataset, look_back=1):
	dataX, dataY = [], []
	for i in range(len(dataset)-look_back-1):
		a = dataset[i:(i+look_back), 0]
		dataX.append(a)
		dataY.append(dataset[i + look_back, 0])
	return numpy.array(dataX), numpy.array(dataY)

#Fix the random number seed to 0 in numpy for reproducibility
numpy.random.seed(0)

#Convert the integer values in the data to floating point values
dataset = dataframe.values
dataset = dataset.astype('float32')

#Normalize the data to range (0 - 1) using MinMaxScaler
Scaler = MinMaxScaler()
dataset = Scaler.fit_transform(dataset)

#Split the first 67% of the data as training data
train_size = int(len(dataset) * 0.67)
test_size = len(dataset) - train_size
#And split the remaining 33% as testing data
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]

#Obtain the two-column input-output dataset
look_back = 1
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

model = Sequential()

#Build the LSTM network with a hidden layer of 4 neurons
model.add(LSTM(4, input_dim=look_back, recurrent_activation='sigmoid', return_sequences=True))

#And an output layer with a single neuron
model.add(Dense(1))

model.compile(loss='mean_squared_error', optimizer='adam')

#Reshape the input data to be in the [samples, time steps, features] format
trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

#Calculate and print the root-mean-squared-error (RMSE) in training and test data
trainScore = model.evaluate(trainX, trainY, verbose=0)
print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))
testScore = model.evaluate(testX, testY, verbose=0)
print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))

#Predict the next month's number of passengers
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

#Reshape the input data
trainPredict = numpy.reshape(trainPredict, (trainPredict.shape[0], trainPredict.shape[1]))
testPredict = numpy.reshape(testPredict, (testPredict.shape[0], testPredict.shape[1]))

# shift train predictions for plotting
trainPredictPlot = numpy.empty_like(dataset)
trainPredictPlot[:, :] = numpy.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict

# shift test predictions for plotting
testPredictPlot = numpy.empty_like(dataset)
testPredictPlot[:, :] = numpy.nan
testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict

# plot baseline and predictions after inverting their values
plt.plot(Scaler.inverse_transform(dataset))
plt.plot(Scaler.inverse_transform(trainPredictPlot))
plt.plot(Scaler.inverse_transform(testPredictPlot))

#Align and plot the actual and predicted values for the entire dataset
plt.show()

"""#d) Predict the next month's value given this month and the previous two months"""

#Obtain the four-columns input-output dataset
look_back = 3
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

model = Sequential()

#Build the LSTM network with a hidden layer of 4 neurons
model.add(LSTM(4, input_dim=look_back, recurrent_activation='sigmoid', return_sequences=True))

#And an output layer with a single neuron
model.add(Dense(1))

model.compile(loss='mean_squared_error', optimizer='adam')

#Reshape the input data to be in the [samples, time steps, features] format
trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)

#Calculate and print the root-mean-squared-error (RMSE) in training and test data
trainScore = model.evaluate(trainX, trainY, verbose=0)
print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))
testScore = model.evaluate(testX, testY, verbose=0)
print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))

#Predict the next month's number of passengers
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

#Reshape the input data
trainPredict = numpy.reshape(trainPredict, (trainPredict.shape[0], trainPredict.shape[1]))
testPredict = numpy.reshape(testPredict, (testPredict.shape[0], testPredict.shape[1]))

# shift train predictions for plotting
trainPredictPlot = numpy.empty_like(dataset)
trainPredictPlot[:, :] = numpy.nan
trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict

# shift test predictions for plotting
testPredictPlot = numpy.empty_like(dataset)
testPredictPlot[:, :] = numpy.nan
testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict

# plot baseline and predictions after inverting their values
plt.plot(Scaler.inverse_transform(dataset))
plt.plot(Scaler.inverse_transform(trainPredictPlot))
plt.plot(Scaler.inverse_transform(testPredictPlot))

#Align and plot the actual and predicted values for the entire dataset
plt.show()

"""#Refrence:

Brownlee, Jason. “Time Series Prediction With Deep Learning in Keras.” Machine Learning Mastery, 27 Aug. 2020, [machinelearningmastery.com/time-series-prediction-with-deep-learning-in-python-with-keras/](https://).
"""